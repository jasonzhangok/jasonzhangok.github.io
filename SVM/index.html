<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.zhangjs.me","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="The past and present of SVM">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM">
<meta property="og:url" content="http://www.zhangjs.me/SVM/index.html">
<meta property="og:site_name" content="Jason&#39;s Blog">
<meta property="og:description" content="The past and present of SVM">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation1.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation2.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation3.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation4.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation5.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation6.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation7.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation8.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation9.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation10.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation11.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation12.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation13.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation14.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation15.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation16.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation17.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation18.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation19.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation20.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation21.png">
<meta property="og:image" content="http://www.zhangjs.me/image/SVM/Equation22.png">
<meta property="article:published_time" content="2024-10-20T16:00:00.000Z">
<meta property="article:modified_time" content="2024-10-22T12:32:43.799Z">
<meta property="article:author" content="Jiasheng Zhang">
<meta property="article:tag" content="ComputerScience">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.zhangjs.me/image/SVM/Equation1.png">


<link rel="canonical" href="http://www.zhangjs.me/SVM/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://www.zhangjs.me/SVM/","path":"SVM/","title":"SVM"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>SVM | Jason's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Jason's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">JiaSheng Zhang's blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section">Home</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section">Archives</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section">Categories</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section">Tags</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section">About</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Past"><span class="nav-number">1.</span> <span class="nav-text">Past</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Present"><span class="nav-number">2.</span> <span class="nav-text">Present</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Future"><span class="nav-number">3.</span> <span class="nav-text">Future</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">4.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jiasheng Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/jasonzhangok" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jasonzhangok" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hi@zhangjs.me" title="E-Mail → mailto:hi@zhangjs.me" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://www.zhangjs.me/SVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jiasheng Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="SVM | Jason's Blog">
      <meta itemprop="description" content="The past and present of SVM">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SVM
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-21 00:00:00" itemprop="dateCreated datePublished" datetime="2024-10-21T00:00:00+08:00">2024-10-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-10-22 20:32:43" itemprop="dateModified" datetime="2024-10-22T20:32:43+08:00">2024-10-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Learning-Notes/" itemprop="url" rel="index"><span itemprop="name">Learning Notes</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">The past and present of SVM</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="Past"><a href="#Past" class="headerlink" title="Past"></a>Past</h1><p>&emsp;&emsp;The origin of SVM can be dated back to 1947 when Frank Rosenblatt has just presented <font color=Red> perceptron</font>. Perceptron is a simple neural network and can classify data points into two parts. However, the perceptron a flaw: it requires the data to be linearly separable, meaning the data points can be perfectly separated by a straight line.<br>&emsp;&emsp;The basic idea of the perceptron are as follows: Suppose that in the $f:R^n $ space, there have n discrete points, denoted as <img src="../image/SVM/Equation1.png" alt="Equation" width="200" >Each of them either have property1 or property2.<br>&emsp;&emsp;We want to draw a hyperplane to seperate these two types of points, that is to say: let one type of points in the one side of the hyperplane.We define di &#x3D; 1 if xi should above the hyperplane and di &#x3D; -1 if xi should below the hyperplane. And we have <img src="../image/SVM/Equation2.png" alt="Equation" width="600" > Then the hyperplane can be expressed as <img src="../image/SVM/Equation3.png" alt="Equation" width="300" > for each discrete point xi, we substitute their coordinates into the hyperplane equation and we can get:<img src="../image/SVM/Equation4.png" alt="Equation" width="300" > if xi is actually above the hyperplane <img src="../image/SVM/Equation5.png" alt="Equation" width="300" > if xi is actually on the hyperplane or below the hyperplane. If di and xi have same sign, then xi is classified corrected, else we need to adjust the hyperplane.<br>&emsp;&emsp;Then we can convert the problem to an optimization problem:<img src="../image/SVM/Equation6.png" alt="Equation" width="300" ><br>where M is the set of all wrong classified points and dis(xi) is the distance between point xi and the hyperplane.We can use gradient descent to solve this optimization problem.<br>&emsp;&emsp;Then, in 1963, Vapnik and his colleagues introduced <font color=Red> SVM</font> to address the limitations of the perceptron model. They pointed out “The Original Maximum Margin Hyperplane Algorithm”. We have $n$ data points: <img src="../image/SVM/Equation7.png" alt="Equation" width="200" > where xi is n-dimension vector and yi is 1 or -1,indicating the class of xi. If the data points are linearly separable, then we can find out two parallel hyperplanes that can seperate all points to their correct class and has the biggest distance between two hyperplanes. We name the two parallel hyperplanes “Maximum Margin Hyperplane “.<br>&emsp;&emsp; Then it is easy to see that all the parallel hyperplanes between Maximum Margin Hyperplane are solution to the classification problem. The two parallel hyperplanes can be expressed as <img src="../image/SVM/Equation8.png" alt="Equation" width="300" >  The distance between is <img src="../image/SVM/Equation9.png" alt="Equation" width="80" >.<br>&emsp;&emsp; We want to maximize the distance between the Maximum Margin Hyperplane. And at the same time, we need to guarantee that for all i, it need to satisify one of the following two conditions:<br><img src="../image/SVM/Equation10.png" alt="Equation" width="300" ><br>The two condition can be expressed together as:  <img src="../image/SVM/Equation11.png" alt="Equation" width="300" ><br>And further more, we can acknowledge that the Maximum Margin Hyperplane are decided absoluately from the closest xi, These xi are called Support Vector.<br>&emsp;&emsp;In 1992, Bernhard E. Boser and Isabelle M. Guyon introduced the <font color=Red> Kernel Function</font> to map the unlinearly separable points to higher dimension space to make them linearly separable. That is to say, make the difference between different parts more significant. Some most used kernels:<img src="../image/SVM/Equation12.png" alt="Equation" width="600" ><br>But It is note-worthing that a higher-dimensional feature space increases the generalization error of the support vector machine,  but given enough samples, the algorithm can still perform well.<br>&emsp;&emsp; In 1993, Corinna Cortes introduced <font color=Red> Soft Margin SVM</font>. They introduced slack variable and penalty factor C Then we want to:<img src="../image/SVM/Equation13.png" alt="Equation" width="400" ><br>and the optimization goal are set as: <img src="../image/SVM/Equation14.png" alt="Equation" width="400" ><br>&emsp;&emsp; In 1990s, with rapid development of Machine learning, Vapnik intorduced Structural Risk Minimization(SRM) in 1970s get more and more attention. SRM is designed to find the best trade-off between a model’s complexity and its ability to generalize to unseen data, helping to prevent overfitting. When it comes to SRM, we have to mention Empirical Risk Minimization(ERM). ERM aims to minimize the error(lose) on training data, it focuses solely on training data. Thus ERM has a fatal flaw: it just focuses on fitting data as accurate as possible, without regard to model complexity, this will lead to overfitting – fit very good on training data but perform poorly on new, unseen data. The cause of overfit is model captures noise or irrelavant features.<br>&emsp;&emsp; SRM can alleviate overfitting by balancing a trade-off between the the model’s fit on the training data and its complexity.Mathematically, SRM minimizes a form of generalization error, which is the sum of the training error and the  of model complexity. The penalty grows with the complexity of the model, reflecting the risk of overfitting.</p>
<h1 id="Present"><a href="#Present" class="headerlink" title="Present"></a>Present</h1><p>&emsp;&emsp; We organize the development history of SVM we can conclude a comprehensive SVM:<br>Two set of data points: <img src="../image/SVM/Equation15.png" alt="Equation" width="825" ><br>But what will happen if there does not eaxist (w,b) that can seperate data points into two parts?<br>We introduce slack variable and penalty factor C, that there exists (w,b) that satisify<br><img src="../image/SVM/Equation16.png" alt="Equation" width="825" ><br>The SVM optimization can actually be seen as a quadratic programming problem:<br><img src="../image/SVM/Equation17.png" alt="Equation" width="825" ><br><img src="../image/SVM/Equation18.png" alt="Equation" width="300" ><br>Since that P is a symmetric positive semidefinite metrix and Gx-h &lt;&#x3D; 0 is a convex function,then it is a convex optimization problem.<br>It’s prove SVM optimization satisifies Slater condition: Let w &#x3D; 0, b &#x3D; 0, slack variable penalty be  2 then we have:<br><img src="../image/SVM/Equation19.png" alt="Equation" width="300" ><br>So the strong duality is satisified. So the SVM has the same optimal solution as its dual problem. And since the inequality constraints of SVM original problem are too much and too complex, we can convert the SVM problem to its dual problem.<br><img src="../image/SVM/Equation20.png" alt="Equation" width="825" ><br><img src="../image/SVM/Equation21.png" alt="Equation" width="825" ><br>That is the dual problem of SVM.<br>&emsp;&emsp; For its powerful classification capability, SVM is not just limited to easy classification tasks, it is widely used in various fields. For example: pattern recognition, Object recognition, image classification, text categorization, Bioinformatics etc.<br>&emsp;&emsp; At the same time,SVM has been integrated with other advanced methods such as evolve algorithms, to enhance<br>the ability of classification and optimize parameters.<br>&emsp;&emsp; However, there are some limitations of SVM. First, the principal disadvantage of SVM is its huge computational cost in large data sets.(i.e. SVM is not suitable for large data set classification) At the same time, Support Vector Machines were originally designed to solve binary classification problems. When it comes to multiclassification, SVM does not present an easy solution. There are some ways to change the multiclassification problem to binary classification problem: one-against-one and one-against-all.<br>&emsp;&emsp; One-against-one method is at each step we take two class of multiclass and find out a set of hyperplanes that can seperate them. Do this until all pair of classes are processed. One-against-all method is at each step we take one class and regard other class as a whole class, we seperate these two “classes” and do this until all the classes are processed. It is easily to acknowledge that the ways to multiclassification require high computational resources and is very time-consuming.</p>
<h1 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h1><p>&emsp;&emsp;Since There are limitations of SVM, we human beings always want to correct theses limitations. For multiclassification problems, Now there exists one-against-one and one-against-all approach. But each of them has their own drawback.<br><img src="../image/SVM/Equation22.png" alt="Equation" width="600" ><br>&emsp;&emsp; So ,for a large number of classes, new heuristic, stochastic or hybrid methods need to be designed to improve classification accuracy. And on thing that I am most interested in is Deep learning and SVM. In recent few years, deep learning has gain more and more attention and thus less attention are put on SVM.<br>&emsp;&emsp; Both of Deep learning and SVM has their own advantages and disadvantages. If we can let them work in synergy, I believe, the performance in some application will be improved.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1]Support vector machine, Wikipedia, <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Support_vector_machine//">https://en.wikipedia.org/wiki/Support_vector_machine\\</a><br>[2]$致敬真神：SVM的进化史, kyle, <a target="_blank" rel="noopener" href="https://www.bytezonex.com/archives/N0UqQYV4.html//">https://www.bytezonex.com/archives/N0UqQYV4.html\\</a><br>[3]Slides in “Fundamental Optimization” in Xi’an Jiaotong University, Minnan Luo\<br>[4]Jair Cervantes,Farid Garcia-Lamont ,Lisbeth Rodríguez-Mazahua,Asdrubal Lopez, “A comprehensive survey on support vector machine classification: Applications, challenges and trends” Neurocomputing Volume 408, 30 September 2020, Pages 189-215\<br>[5]M. A. Cano Lengua and E. A. Papa Quiroz, “A Systematic Literature Review on Support Vector Machines Applied to Classification,” 2020 IEEE Engineering International Research Conference (EIRCON), Lima, Peru, 2020, pp. 1-4, doi10.1109&#x2F;EIRCON51178.2020.9254028.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ComputerScience/" rel="tag"># ComputerScience</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/MOT_LiteratureReivew/" rel="prev" title="Literautre review of MOT">
                  <i class="fa fa-angle-left"></i> Literautre review of MOT
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Jiasheng Zhang</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
