<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.zhangjs.me","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="The past and present of SVM">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM">
<meta property="og:url" content="http://www.zhangjs.me/SVM/index.html">
<meta property="og:site_name" content="Jason&#39;s Blog">
<meta property="og:description" content="The past and present of SVM">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-10-20T16:00:00.000Z">
<meta property="article:modified_time" content="2024-10-21T05:20:18.277Z">
<meta property="article:author" content="Jiasheng Zhang">
<meta property="article:tag" content="ComputerScience">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://www.zhangjs.me/SVM/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://www.zhangjs.me/SVM/","path":"SVM/","title":"SVM"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>SVM | Jason's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Jason's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">JiaSheng Zhang's blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section">Home</a></li><li class="menu-item menu-item-archives"><a href="/archives" rel="section">Archives</a></li><li class="menu-item menu-item-categories"><a href="/categories" rel="section">Categories</a></li><li class="menu-item menu-item-tags"><a href="/tags" rel="section">Tags</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section">About</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Jiasheng Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/jasonzhangok" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jasonzhangok" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hi@zhangjs.me" title="E-Mail → mailto:hi@zhangjs.me" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://www.zhangjs.me/SVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Jiasheng Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jason's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="SVM | Jason's Blog">
      <meta itemprop="description" content="The past and present of SVM">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SVM
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-10-21 00:00:00 / Modified: 13:20:18" itemprop="dateCreated datePublished" datetime="2024-10-21T00:00:00+08:00">2024-10-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Learning-Notes/" itemprop="url" rel="index"><span itemprop="name">Learning Notes</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">The past and present of SVM</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>The origin of SVM can be dated back to 1947 when Frank Rosenblatt has just presented \textcolor{red}{perceptron}. Perceptron is a<br>simple neural network and can classify data points into two parts. However, the perceptron a flaw: it requires the data to be linearly separable,<br>meaning the data points can be perfectly separated by a straight line.\<br>\indent The basic idea of the perceptron are as follows:<br>Suppose that in the $f: \mathbb{R}^n$ space, there have $n$ discrete points, denoted as ${x_1, x_2, \cdots ， x_n}$<br>Each of them either have property1 or property2. \<br>\indent We want to draw a hyperplane to seperate these two types of points, that is to say: let one type of points in the one side of the hyperplane.<br>We define $d_i &#x3D; 1$ if $x_i$ should above the hyperplane and $d_i &#x3D; -1$ if $x_i$ should below the hyperplane.\<br>\indent And we have $\bm{w} &#x3D; [w_0, w_1, \cdots ， w_n]$<br>$\bm{x} &#x3D; [1 , coord_1, coord_2, \cdots ， coord_n]$\<br>\indent Then the hyperplane can be expressed as $ l:\bm{w}^T \bm{x} &#x3D; 0$<br>for each discrete point $x_i$, we substitute their coordinates into the hyperplane equation and we can get\<br>$f(x_i): \bm{w}^T \bm{x}<em>i &gt;0 $ if $x_i$ is actually above the hyperplane<br>$f(x_i): \bm{w}^T \bm{x_i} \leq 0 $ if $x_i$ is actually on the hyperplane or below the hyperplane<br>If $d_i$ and $f(x_i)$ have same sign, then $x_i$ is classified corrected, else we need to adjust the hyperplane.\<br>\indent Then we can convert the problem to an optimization problem:\<br>$min J(\bm(w)) &#x3D; \sum\limits</em>{x_i \in M} -d_i · dis(\bm{x_i})$\<br>where $M$ is the set of all wrong classified points and $dis(\bm{x_i})$ is the distance between point$x_i$ and the hyperplane.<br>We can use gradient descent to solve this optimization problem.\</p>
<p>Then, in 1963, Vapnik and his colleagues introduced \textcolor{red}{SVM} to address the limitations of the perceptron model.<br>They pointed out “The Original Maximum Margin Hyperplane Algorithm”. We have $n$ data points: $(\bm{x_1},y_1),(\bm{x_2},y_2),\cdots, (\bm{x_n},y_n) $ where $\bm{x_i}$ is n-dimension vector and $y_i$ is 1 or -1,indicating the class of $\bm{x_i}$.<br>If the data points are linearly separable,<br>then we can find out two parallel hyperplanes that can seperate all points to their correct class and has the biggest distance between two hyperplanes.<br>We name the two parallel hyperplanes “Maximum Margin Hyperplane “.<br>Then it is easy to see that all the parallel hyperplanes between Maximum Margin Hyperplane are solution to the classification problem.\<br>\indent The two parallel hyperplanes can be expressed as $ \bm{w}\bm{x} + b &#x3D; 1$ and $ \bm{w}\bm{x} + b &#x3D; -1$  The distance between is $\frac{2}{\Vert \bm{w} \Vert}$.<br>We want to maximize the distance between the Maximum Margin Hyperplane. And at the same time, we need to guarantee that for all $i$, it need to satisify one of the following two conditions:\<br>$\bm{w}\bm{x_i} + b \geq 1$ and $y_i &#x3D; 1$\<br>$\bm{w}\bm{x_i} + b \leq 1$ and $y_i &#x3D; -1$\<br>The two condition can be expressed together as:  $y_i(\bm{w}\bm{x_i} + b) \geq 1$ for all $i$<br>And further more, we can acknowledge that the Maximum Margin Hyperplane are decided absoluately from the closest $\bm{x_i}$, These $\bm{x_i}$ are called Support Vector.\<br>\indent In 1992, Bernhard E. Boser and Isabelle M. Guyon introduced the \textcolor{red}{kernel function} to map the unlinearly separable points to higher dimension space to make them linearly separable.<br>That is to say, make the difference between different parts more significant. But It is note-worthing that a higher-dimensional feature space increases the generalization error of the support vector machine,<br>but given enough samples, the algorithm can still perform well.\<br>\indent In 1993, Corinna Cortes introduced \textcolor{red}{Soft Margin SVM}. They introduced slack variable $\xi_k$ and penalty factor $C$ Then we want to:<br>$y_i(\bm{w}\bm{x_i} + b) \geq 1 - \xi_i $ for all $i$ \<br>and the optimization goal are set as: $min   \frac{1}{2}\Vert \bm{w} \Vert^2 + C\sum_{k&#x3D;1}^{k&#x3D;n}\xi_k$\<br>\indent In 1990s, with rapid development of Machine learning, Vapnik intorduced Structural Risk Minimization(SRM) in 1970s get more and more attention.<br>SRM is designed to find the best trade-off between a model’s complexity and its ability to generalize to unseen data, helping to prevent overfitting.\<br>\indent When it comes to SRM, we have to mention Empirical Risk Minimization(ERM). ERM aims to minimize the error(lose) on training data, it focuses solely on training data.<br>Thus ERM has a fatal flaw: it just focuses on fitting data as accurate as possible, without regard to model complexity, this will lead to overfitting<br>– fit very good on training data but perform poorly on new, unseen data. The cause of overfit is model captures noise or irrelavant features.\<br>\indent SRM can alleviate overfitting by balancing a trade-off between the the model’s fit on the training data and its complexity.<br>Mathematically, SRM minimizes a form of generalization error, which is the sum of the training error and the  of model complexity.<br>The penalty grows with the complexity of the model, reflecting the risk of overfitting.</p>
<p>\section{Present}<br>We organize the development history of SVM we can conclude a comprehensive SVM:\<br>Two set of data points:\<br>$C1 &#x3D; {x_i \in \mathbb{R}^n:i &#x3D; 1,2,\cdots ,m}$, $C2 &#x3D; {x_i \in \mathbb{R}^n:i &#x3D; m+1,m+2,\cdots ,m+n}$\<br>Learn the hyperplane parameters $w \in \mathbb{R}^n $ and $b \in \mathbb{R}$ that:\<br>$w^Tx_i + b &gt; 0, (i &#x3D; 1,2,\cdots,m)$ \<br>$w^Tx_j + b &lt; 0, (j &#x3D; m+1,m+2,\cdots,m+n)$<br>Maximize the shortest distance from data point to hyperplane:\<br>$\max\limits_{w,b} min {\Vert x - x_k \Vert_2: w^Tx + b&#x3D;0, k &#x3D; 1,2,\cdots,m+n}$\<br>That make the shortest distance data points on the two hyperplanes $w^Tx_i + b &#x3D;\pm 1 $respectively, so that\<br>$w^Tx_i + b \geq 0, (i &#x3D; 1,2,\cdots,m)$ \<br>$w^Tx_j + b \leq 0, (j &#x3D; m+1,m+2,\cdots,m+n)$<br>The distance between two hyperplanes $H1 &#x3D; {z: w^Tz + b &#x3D;1}$ and $H2 &#x3D; {z: w^Tz + b &#x3D; -1}$ is $\frac{2}{\Vert \bm{w} \Vert}$\<br>Then we can make the optimization problem:\<br>$\min\limits_{w \in \mathbb{R}^n,b \in \mathbb{R}} \frac{1}{2} \Vert w \Vert_2$\<br>$s.t. w^Tx_i + b \geq 1, (i &#x3D; 1,2,\cdots,m)$ \<br>$w^Tx_j + b \leq -1, (j &#x3D; m+1,m+2,\cdots,m+n)$\<br>Positive label $y_i &#x3D; 1,(i &#x3D; 1,2,\cdots,m)$\<br>Negative label $y_j &#x3D; -1,(j &#x3D; m+1,m+2,\cdots,m+n)$\<br>We can get:\<br>$\min\limits_{w \in \mathbb{R}^n,b \in \mathbb{R}} \frac{1}{2} \Vert w \Vert_2$\<br>$s.t. y_i(w^Tx_i + b) \geq 1, (i &#x3D; 1,2,\cdots,m+n)$ \<br>But what will happen if there does not eaxist $(w,b)$ that can seperate data points into two parts?\<br>We introduce slack variable $\xi_k$ and penalty factor $C$, that there exists $(w,b)$ that satisify $y_k(w^Tx_k + b) \geq 1 - \xi_k, (i &#x3D; 1,2,\cdots,m+n)$\<br>That the optimization problem can be converted into:\<br>$\min\limits_{w \in \mathbb{R}^n,b \in \mathbb{R},\xi_k(\forall k)} \frac{1}{2} \Vert w \Vert_2 + C\sum_{k&#x3D;1}^{k&#x3D;n}\xi_k$\<br>$y_k(w^Tx_k + b) \geq 1 - \xi_k, (i &#x3D; 1,2,\cdots,m+n)$\<br>$\xi_k \geq 0 (k &#x3D; 1,2,\cdot, m+n)$\<br>There are three optimized variables: $w \in \mathbb{R}^n, \xi &#x3D; [\xi_1,\xi_2,\cdots,\xi_m+n]^T \in \mathbb{R}^m+n, b \in \mathbb{R} $\<br>The SVM optimization can actually be seen as a quadratic programming problem:\<br>$$<br>\begin{gathered}<br>    $ x&#x3D; $<br>    \left[<br>        \begin{array}{cccc}<br>            w \<br>            \xi \<br>            b<br>        \end{array}<br>    \right]<br>    $,P &#x3D; $<br>    \left[<br>        \begin{array}{cccc}<br>            I &amp; 0 &amp; 0 \<br>            0 &amp; 0 &amp; 0 \<br>            0 &amp; 0 &amp; 0<br>        \end{array}<br>    \right]<br>    $,c &#x3D; $<br>    \left[<br>        \begin{array}{cccc}<br>            0 \<br>            C · 1 \<br>            0<br>        \end{array}<br>    \right]<br>    $,G &#x3D; $<br>    \left[<br>        \begin{array}{cccc}<br>            -diag(y)X &amp; -I &amp; -y \<br>            0 &amp; -I &amp; 0 \<br>        \end{array}<br>    \right]<br>\end{gathered}<br>$$\<br>$$<br>\begin{gathered}<br>    $ y&#x3D; $<br>    \left[<br>        \begin{array}{cccc}<br>            y_1 \<br>            y_2 \<br>            \cdots \<br>            y_{m+n}<br>        \end{array}<br>    \right]<br>    $ X&#x3D; $<br>    \left[<br>        \begin{array}{cccc}<br>            x_1^T \<br>            x_2^T \<br>            \cdots \<br>            x_{m+n}<br>        \end{array}<br>    \right]<br>    $ h&#x3D; $<br>    \left[<br>        \begin{array}{cccc}<br>            -1 \<br>            0 \<br>        \end{array}<br>    \right]<br>\end{gathered}<br>$$\</p>
<p>\noindent $min \frac{1}{2}x^TPx + c^Tx + d$\<br>$s.t. Gx \leq h$\<br>$\xi_k \geq 0$\</p>
<p>Since that P is a symmetric positive semidefinite metrix and $Gx-h \leq 0$ is a convex function,<br>then it is a convex optimization problem.\<br>It’s prove SVM optimization satisifies Slater condition: Let $w &#x3D; 0, b &#x3D; 0, \xi_k &#x3D; 2$ then we have:\<br>$y_k(w^Tx_k + b) &#x3D; 0 &gt; 1 - \xi_k &#x3D; 1-2 &#x3D; -1$\<br>So the strong duality is satisified. So the SVM has the same optimal solution as its dual problem.\<br>And since the inequality constraints of SVM original problem are too much and too complex, we can convert<br>the SVM problem to  its dual problem.\<br>The dual problem:<br>Lagrange function: \<br>$L(w,b,\xi,\alpha,\beta) &#x3D; \frac{1}{2}\Vert w \Vert_2^2 + C \sum\limits_{k&#x3D;1}^{m+n}\xi - \sum\limits_{k&#x3D;1}^{m+n}\alpha_k(y_k(w^Tx_k + b) - 1 + \xi_k) - \sum\limits_{k&#x3D;1}^{m+n}\beta_k\xi_k$\<br>Lagrange dual function:\<br>$g(\alpha,\beta) &#x3D; \min\limits_{w,b,\xi}L(w,b,\xi,\alpha,\beta)$\<br>Lagrange dual problem: $\max\limits_{\alpha \geq 0, \beta \geq 0}g(\alpha,\beta)$\<br>To be more precise:\<br>$g(\alpha,\beta) &#x3D; \min\limits_{w,b,\xi}L(w,b,\xi,\textcolor{red}{\alpha,\beta}) &#x3D; \min\limits_{w,b,\xi} \frac{1}{2}\Vert w \Vert_2^2 + C \sum\limits_{k&#x3D;1}^{m+n}\xi - \sum\limits_{k&#x3D;1}^{m+n}\alpha_k(y_k(w^Tx_k + b) - 1 + \xi_k) - \sum\limits_{k&#x3D;1}^{m+n}\beta_k\xi_k$\<br>Since when we get optimal value of $\min\limits_{w,b,\xi}L(w,b,\xi,\alpha,\beta)$, the partial difference for $w,b,\xi$ are 0, then we have\<br>$\frac{\partial L(w,b,\xi,\alpha,\beta)}{\partial w} &#x3D;0 \rightarrow w &#x3D; \sum\limits_{k&#x3D;1}^{m+n}\alpha_k y_k x_k$\<br>$\frac{\partial L(w,b,\xi,\alpha,\beta)}{\partial b} &#x3D;0 \rightarrow \sum\limits_{k&#x3D;1}^{m+n}\alpha_k y_k$\<br>$\frac{\partial L(w,b,\xi,\alpha,\beta)}{\partial \xi} &#x3D;0 \rightarrow \alpha_k + \beta_k &#x3D; C$\</p>
<p>\noindent $g(\alpha,\beta) &#x3D; \min\limits_{\alpha} \sum\limits_{k&#x3D;1}^{m+n} \sum\limits_{s&#x3D;1}^{m+n}\alpha_k a_s y_k y_s x_i^T x_j - \sum\limits_{k&#x3D;1}^{m+n} \alpha_k$\<br>$s.t. 0 \leq \alpha_k \leq C, i &#x3D; 1,2,3, \cdots,m+n$<br>$\sum\limits_{k&#x3D;1}^{m+n}\alpha_k y_k &#x3D; 0$\<br>That is the dual problem of SVM.</p>
<p>\section{Future}</p>
<p>\end{document}</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ComputerScience/" rel="tag"># ComputerScience</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/MOT_LiteratureReivew/" rel="prev" title="Literautre review of MOT">
                  <i class="fa fa-angle-left"></i> Literautre review of MOT
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Jiasheng Zhang</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
